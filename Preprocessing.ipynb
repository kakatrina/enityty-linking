{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Json File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all sections tag included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(json_toload):\n",
    "    js= json.load(open(json_toload))\n",
    "    d=[]\n",
    "    for j in range(len(js['rows'])):\n",
    "        data_dict={}\n",
    "        title=js[\"rows\"][j][\"title\"]\n",
    "        cont=\"\".join(js[\"rows\"][j][\"content\"])\n",
    "        time=js[\"rows\"][j]['lastupdated']['iso8601']\n",
    "        section=js[\"rows\"][j]['sections']\n",
    "        content=unidecode(cont)\n",
    "        soup = BeautifulSoup(content, 'lxml')\n",
    "        \n",
    "        [tagstring.extract() for tagstring in soup('script')] ### extracts all content not between balance <script> tags\n",
    "        [tagstring.extract() for tagstring in soup('table')] ### extracts all content not between balance <table> tags\n",
    "        [tagstring.extract() for tagstring in soup('iframe')] ### extracts all content not between balance <iframe> tags\n",
    "        [tagstring.extract() for tagstring in soup('blockquote')] ### extracts all content not between balance <iblockquote> tags\n",
    "        [tagstring.extract() for tagstring in soup('ol')] ### extracts all content not between balance <ol> tags\n",
    "        [tagstring.extract() for tagstring in soup('ul')] ### extracts all content not between balance <ul> tags\n",
    "        [tagstring.extract() for tagstring in soup('h1')] ### extracts all content not between balance <h1> tags\n",
    "        [tagstring.extract() for tagstring in soup('h2')] ### extracts all content not between balance <h2> tags\n",
    "        [tagstring.extract() for tagstring in soup('h3')] ### extracts all content not between balance <h3> tags\n",
    "        [tagstring.extract() for tagstring in soup('h4')] ### extracts all content not between balance <h4> tags\n",
    "        [tagstring.extract() for tagstring in soup('h5')] ### extracts all content not between balance <h5> tags\n",
    "        [tagstring.extract() for tagstring in soup('img')] ### extracts all content not between balance <img> tags\n",
    "        filtered_content = soup.find_all('p')\n",
    "        moment = \"\"\n",
    "        for wrapped_paragraph in filtered_content:\n",
    "            moment+= str(wrapped_paragraph.wrap)+\" \"\n",
    "\n",
    "            content = re.sub(r\"<bound.*?>\",\" \",content).strip() ###some article begin with this\n",
    "            content= re.sub(r'/^(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)*\\/?$/', ' ', content,re.MULTILINE)\n",
    "            content = re.sub(r\"<\\!--.*\",\" \",content,re.DOTALL)\n",
    "            content = re.sub(r\"\\.\\s{,2}\\.\\s\",\". \",content,re.DOTALL)\n",
    "            content = re.sub(r\"\\[.*?\\]\",\" \",content,re.DOTALL)\n",
    "            content = re.sub(r\"\\<span.*?</span\\>\",\" \",content,re.DOTALL)\n",
    "            content = content.replace('<div itemprop=\"reviewBody\">',\" \") ###some article begin with this\n",
    "            content = content.replace(\"@\",\" \")\n",
    "            content = content.replace(\"|\",\" \")\n",
    "            content = content.replace(\"/\",\",\")\n",
    "            content = content.replace(\"(\",\",\")\n",
    "            content = content.replace(\")\",\" \")\n",
    "            content = content.replace(\"---\",\". \")\n",
    "            content = content.replace(\"$\",\" \")\n",
    "            content = re.sub(r\"<.*?>\",\" \" ,content,1000,re.DOTALL)\n",
    "            data_dict=dict([('title',title),('time',time),('section',section),('content',content)])\n",
    "        d.append(data_dict)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in glob.glob(r'C:\\Users\\yueyu\\OneDrive\\桌面\\Corpus\\*.json'):\n",
    "    data.append(cleanup(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'business/consumer'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[33][1]['section'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "combine=[]\n",
    "for i in data:\n",
    "    for j in i:\n",
    "        combine.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.DataFrame(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('clean_article_in_dict.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "m=pd.read_csv('clean_article_in_dict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop dulicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=m.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('noDup_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
